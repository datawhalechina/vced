{
    "summary": "The code sets Jina environment variables, checks device availability for CLIP model loading, and defines functions to retrieve documents, measure time, cut videos, and process search results. The code sets up a Flow object with multiple components, including videoLoader, customClipImage, and customClipText for data processing, using an indexer component with the customIndexer. It is configured to use gRPC protocol and JINA_PORT environment variable and executed in a context manager to process data.",
    "details": [
        {
            "comment": "This code sets environment variables for Jina, checks the device for loading the CLIP model, and defines functions to get documents from a specified data path. The environment variables include the port for accessing the RESTful service, the workspace directory for storing indexed data, and the maximum number of results to return. The device variable is set based on whether CUDA is available and the JINA_MP_START_METHOD environment variable is set to \"spawn\". The code then prints the device used for loading the CLIP model.",
            "location": "\"/media/root/Prima/works/vced/docs/src/code/service/app.py\":0-26",
            "content": "from docarray import Document\nfrom jina import Flow, DocumentArray\nimport os\nimport glob\nfrom jina.types.request.data import DataRequest\nimport torch\ndef config():\n    os.environ['JINA_PORT'] = '45679'  # the port for accessing the RESTful service, i.e. http://localhost:45678/docs\n    os.environ['JINA_WORKSPACE'] = './workspace'  # the directory to store the indexed data\n    os.environ['TOP_K'] = '20'  # the maximal number of results to return\n    os.environ['DEVICE'] = 'cuda'  # the device for model, should be \"cpu\" or \"cuda\". For usage of cuda, should set env JINA_MP_START_METHOD=\"spawn\" before starting Jina & Python. ref: https://github.com/jina-ai/jina/issues/2514 \ndef check_device():\n    device = \"cpu\"\n    if (\n        os.environ.get(\"DEVICE\") == \"cuda\" and \n        torch.cuda.is_available() and\n        os.environ.get(\"JINA_MP_START_METHOD\") == \"spawn\"\n    ):\n        device = \"cuda\"\n    print(f\"The CLIP model is loaded on device: {device}\")\n    return device   \ndef get_docs(data_path):\n    for fn in glob.glob(os.path.join(data_path, '*.mp4')):"
        },
        {
            "comment": "The code contains several functions. `check_index` prints the URI of each document in a response. `getTime` calculates and prints the time in hours, minutes, and seconds. `cutVideo` cuts a video segment based on start time and length, saving it to a user-specific directory using ffmpeg. `check_search` processes search results by printing the query text, number of matches, and detailed information about each match.",
            "location": "\"/media/root/Prima/works/vced/docs/src/code/service/app.py\":27-60",
            "content": "        yield Document(uri=fn, id=os.path.basename(fn))\ndef check_index(resp: DataRequest):\n    for doc in resp.docs:\n        print(f'check_index: {doc.uri}')\ndef getTime(t: int):\n    m, s = divmod(t, 60)\n    h, m = divmod(m, 60)\n    t_str = \"%02d:%02d:%02d\" % (h, m, s)\n    print(t_str)\n    return t_str\ndef cutVideo(start_t: str, length: int, input: str, output: str, uid: str):\n    user_dir = os.path.join('static', 'output', uid)\n    if not os.path.exists(user_dir):\n        os.mkdir(user_dir)\n    os.system(f'ffmpeg -ss {start_t} -i {input} -t {length} -c:v copy -c:a copy {user_dir}/{output}')\ndef check_search(resp: DataRequest):\n    for i, doc in enumerate(resp.docs):\n        print(f'Query text: {doc.text}')\n        print(f'Matches: {len(doc.matches)}')\n        for m in doc.matches:\n            print(m)\n            print(\n                f'+- id: {m.id}, score: {m.tags[\"maxImageScore\"]}, indexRange: {m.tags[\"leftIndex\"]}-{m.tags[\"rightIndex\"]}, uri: {m.tags[\"uri\"]}')\n        print('-' * 10)\n        leftIndex = doc.matches[0].tags[\"leftIndex\"]"
        },
        {
            "comment": "The code sets up a Flow object with multiple components, including videoLoader, customClipImage, and customClipText for data processing. It also includes an indexer component using the customIndexer. The Flow is configured to use gRPC protocol and the JINA_PORT environment variable. The code then executes the Flow's block in a context manager to process data.",
            "location": "\"/media/root/Prima/works/vced/docs/src/code/service/app.py\":61-93",
            "content": "        rightIndex = doc.matches[0].tags[\"rightIndex\"]\n        t_str = getTime(leftIndex)\n        # cutVideo(t_str, rightIndex - leftIndex, doc.matches[0].tags[\"uri\"], f\"match_{i}_{doc.matches[0].id}.mp4\")\nif __name__ == '__main__':\n    config()\n    device = check_device()\n    f = Flow(protocol=\"grpc\", port=os.environ['JINA_PORT']).add(\n        uses='videoLoader/config.yml',\n        uses_requests={\"/index\": \"extract\"},\n        name=\"video_loader\"\n    ).add(\n        uses=\"customClipImage/config.yml\",\n        name=\"image_encoder\",\n        uses_requests={\"/index\": \"encode\"},\n        uses_with={\"device\": device}\n    ).add(\n        uses=\"customClipText/config.yml\",\n        name=\"text_encoder\",\n        uses_requests={\"/search\": \"encode\"},\n        uses_with={\"device\": device}\n    ).add(\n        uses=\"customIndexer/config.yml\",\n        name=\"indexer\",\n        uses_metas={\"workspace\": os.environ['JINA_WORKSPACE']}\n    )\n    with f:\n        f.block()"
        }
    ]
}